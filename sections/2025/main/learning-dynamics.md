# ICML-2025-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICML-2025-Papers/blob/main/sections/2025/main/applications-in-computer-vision.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICML-2025-Papers/blob/main/README.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICML-2025-Papers/blob/main/sections/2025/main/theory-and-phenomenology.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Learning Dynamics

![Section Papers](https://img.shields.io/badge/Section%20Papers-8-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-3-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-3-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-1-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| [Algorithm Development in Neural Networks: Insights from the Streaming Parity Task](https://icml.cc/virtual/2025/poster/46526) | :heavy_minus_sign: | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/46526) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2507.09897-b31b1b.svg)](http://arxiv.org/abs/2507.09897) | :heavy_minus_sign: |
| [Strategy Coopetition Explains the Emergence and Transience of In-Context Learning](https://icml.cc/virtual/2025/poster/44561) | [![GitHub](https://img.shields.io/github/stars/aadityasingh/icl-dynamics?style=flat)](https://github.com/aadityasingh/icl-dynamics) | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/44561) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2503.05631-b31b1b.svg)](http://arxiv.org/abs/2503.05631) | :heavy_minus_sign: |
| [Learning Dynamics in Continual Pre-Training for Large Language Models](https://icml.cc/virtual/2025/poster/45051) | :heavy_minus_sign: | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/45051) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2505.07796-b31b1b.svg)](http://arxiv.org/abs/2505.07796) | :heavy_minus_sign: |
| [Transformative or Conservative? Conservation laws for ResNets and Transformers](https://icml.cc/virtual/2025/poster/44796) | [![GitHub](https://img.shields.io/github/stars/sibyllema/Conservation-laws-for-ResNets-and-Transformers?style=flat)](https://github.com/sibyllema/Conservation-laws-for-ResNets-and-Transformers) | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/44796) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2506.06194-b31b1b.svg)](http://arxiv.org/abs/2506.06194) | :heavy_minus_sign: |
| [LoRA Training Provably Converges to a Low-Rank Global Minimum or It Fails Loudly (But it Probably Won't Fail)](https://icml.cc/virtual/2025/poster/44076) | :heavy_minus_sign: | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/44076) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2502.09376-b31b1b.svg)](http://arxiv.org/abs/2502.09376) | :heavy_minus_sign: |
| [Learning Dynamics in Linear Recurrent Neural Networks](https://icml.cc/virtual/2025/poster/45649) | :heavy_minus_sign: | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/45649) | :heavy_minus_sign: |
| [Implicit Regularization for Tubal Tensor Factorizations via Gradient Descent](https://icml.cc/virtual/2025/poster/46592) | [![GitHub](https://img.shields.io/github/stars/AnnaVeselovskaUA/tubal-tensor-implicit-reg-GD?style=flat)](https://github.com/AnnaVeselovskaUA/tubal-tensor-implicit-reg-GD) | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/46592) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2410.16247-b31b1b.svg)](http://arxiv.org/abs/2410.16247) | :heavy_minus_sign: |
| [LoRA-One: One-Step Full Gradient Could Suffice for Fine-Tuning Large Language Models, Provably and Efficiently](https://icml.cc/virtual/2025/poster/45618) | [![GitHub](https://img.shields.io/github/stars/YuanheZ/LoRA-One?style=flat)](https://github.com/YuanheZ/LoRA-One) | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/45618) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2502.01235-b31b1b.svg)](http://arxiv.org/abs/2502.01235) | :heavy_minus_sign: |
