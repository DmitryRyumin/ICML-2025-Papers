# ICML-2025-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICML-2025-Papers/blob/main/sections/2025/main/learning-theory.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICML-2025-Papers/blob/main/README.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICML-2025-Papers/blob/main/sections/2025/main/deep-learning-architectures.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Applications in Agents and Coding

![Section Papers](https://img.shields.io/badge/Section%20Papers-4-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-3-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-2-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| [ITBench: Evaluating AI Agents across Diverse Real-World IT Automation Tasks](https://icml.cc/virtual/2025/poster/44303) | [![GitHub](https://img.shields.io/github/stars/itbench-hub/ITBench?style=flat)](https://github.com/itbench-hub/ITBench) | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/44303) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2502.05352-b31b1b.svg)](http://arxiv.org/abs/2502.05352) | :heavy_minus_sign: |
| [EmbodiedBench: Comprehensive Benchmarking Multi-Modal Large Language Models for Vision-Driven Embodied Agents](https://icml.cc/virtual/2025/poster/45994) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://embodiedbench.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/EmbodiedBench/EmbodiedBench?style=flat)](https://github.com/EmbodiedBench/EmbodiedBench) | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/45994) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2502.09560-b31b1b.svg)](http://arxiv.org/abs/2502.09560) | :heavy_minus_sign: |
| [SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance Software Engineering?](https://icml.cc/virtual/2025/poster/43573) | [![GitHub](https://img.shields.io/github/stars/openai/SWELancer-Benchmark?style=flat)](https://github.com/openai/SWELancer-Benchmark) | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/43573) | :heavy_minus_sign: |
| [CodeIO: Condensing Reasoning Patterns via Code Input-Output Prediction](https://icml.cc/virtual/2025/poster/44514) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://codei-o.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/hkust-nlp/CodeIO?style=flat)](https://github.com/hkust-nlp/CodeIO) | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/44514) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2502.07316-b31b1b.svg)](http://arxiv.org/abs/2502.07316) | :heavy_minus_sign: |
