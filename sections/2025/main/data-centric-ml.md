# ICML-2025-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICML-2025-Papers/blob/main/sections/2025/main/representations.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICML-2025-Papers/blob/main/README.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICML-2025-Papers/blob/main/sections/2025/main/optimization.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Data-Centric ML

![Section Papers](https://img.shields.io/badge/Section%20Papers-4-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-4-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-2-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| [Improving the Scaling Laws of Synthetic Data with Deliberate Practice](https://icml.cc/virtual/2025/poster/46689) | :heavy_minus_sign: | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/46689) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2502.15588-b31b1b.svg)](http://arxiv.org/abs/2502.15588) | :heavy_minus_sign: |
| [Outlier Gradient Analysis: Efficiently Identifying Detrimental Training Samples for Deep Learning Models](https://icml.cc/virtual/2025/poster/43693) | :heavy_minus_sign: | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/43693) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2405.03869-b31b1b.svg)](http://arxiv.org/abs/2405.03869) | :heavy_minus_sign: |
| [Foundation Model Insights and a Multi-Model Approach for Superior Fine-Grained One-Shot Subset Selection](https://icml.cc/virtual/2025/poster/44840) | [![GitHub](https://img.shields.io/github/stars/ZhijingWan/RAM-APL?style=flat)](https://github.com/ZhijingWan/RAM-APL) | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/44840) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2506.14473-b31b1b.svg)](http://arxiv.org/abs/2506.14473) | :heavy_minus_sign: |
| [SK-VQA: Synthetic Knowledge Generation at Scale for Training Context-Augmented Multimodal LLMs](https://icml.cc/virtual/2025/poster/45942) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://github.com/IntelLabs/multimodal_cognitive_ai/tree/main/SK-VQA) <br /> [![GitHub](https://img.shields.io/github/stars/IntelLabs/multimodal_cognitive_ai?style=flat)](https://github.com/IntelLabs/multimodal_cognitive_ai) <br /> [![Hugging Face Dataset](https://img.shields.io/badge/ðŸ¤—-dataset-FFD21F.svg)](https://huggingface.co/datasets/Intel/SK-VQA) | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/45942) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2406.19593-b31b1b.svg)](http://arxiv.org/abs/2406.19593) | :heavy_minus_sign: |
