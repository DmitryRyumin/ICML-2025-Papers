# ICML-2025-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICML-2025-Papers/blob/main/sections/2025/main/applications-in-agents-and-coding.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICML-2025-Papers/blob/main/README.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICML-2025-Papers/blob/main/sections/2025/main/evaluation.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Deep Learning Architectures

![Section Papers](https://img.shields.io/badge/Section%20Papers-4-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-3-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-4-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| [Retrieval-Augmented Perception: High-Resolution Image Perception Meets Visual RAG](https://icml.cc/virtual/2025/poster/44979) | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://dreammr.github.io/RAP) <br /> [![GitHub](https://img.shields.io/github/stars/DreamMr/RAP?style=flat)](https://github.com/DreamMr/RAP) | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/44979) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2503.01222-b31b1b.svg)](http://arxiv.org/abs/2503.01222) | :heavy_minus_sign: |
| [AutoGFM: Automated Graph Foundation Model with Adaptive Architecture Customization](https://icml.cc/virtual/2025/poster/44539) | :heavy_minus_sign: | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/44539) | :heavy_minus_sign: |
| [In-Context Denoising with One-Layer Transformers: Connections between Attention and Associative Memory Retrieval](https://icml.cc/virtual/2025/poster/45913) | [![GitHub](https://img.shields.io/github/stars/mattsmart/in-context-denoising?style=flat)](https://github.com/mattsmart/in-context-denoising) | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/45913) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2502.05164-b31b1b.svg)](http://arxiv.org/abs/2502.05164) | :heavy_minus_sign: |
| [Normalizing Flows are Capable Generative Models](https://icml.cc/virtual/2025/poster/46564) | [![GitHub](https://img.shields.io/github/stars/apple/ml-tarflow?style=flat)](https://github.com/apple/ml-tarflow) | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/46564) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2412.06329-b31b1b.svg)](http://arxiv.org/abs/2412.06329) | :heavy_minus_sign: |
