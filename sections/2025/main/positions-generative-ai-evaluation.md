# ICML-2025-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICML-2025-Papers/blob/main/sections/2025/main/causality-and-domain-generalization.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICML-2025-Papers/blob/main/README.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICML-2025-Papers/blob/main/sections/2025/main/privacy-and-uncertainty-quantification.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Positions: Generative AI Evaluation

![Section Papers](https://img.shields.io/badge/Section%20Papers-4-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-3-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-1-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| [Position: Principles of Animal Cognition to Improve LLM Evaluations](https://icml.cc/virtual/2025/poster/40117) | :heavy_minus_sign: | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/40117) | :heavy_minus_sign: |
| [Position: Political Neutrality in AI is Impossible - But Here is how to Approximate it](https://icml.cc/virtual/2025/poster/40157) | [![GitHub](https://img.shields.io/github/stars/jfisher52/Approximation_Political_Neutrality?style=flat)](https://github.com/jfisher52/Approximation_Political_Neutrality) | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/40157) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2503.05728-b31b1b.svg)](http://arxiv.org/abs/2503.05728) | :heavy_minus_sign: |
| [Position: AI Competitions Provide the Gold Standard for Empirical Rigor in GenAI Evaluation](https://icml.cc/virtual/2025/poster/40139) | :heavy_minus_sign: | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/40139) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2505.00612-b31b1b.svg)](http://arxiv.org/abs/2505.00612) | :heavy_minus_sign: |
| [Position: Medical Large Language Model Benchmarks Should Prioritize Construct Validity](https://icml.cc/virtual/2025/poster/40129) | :heavy_minus_sign: | [![icml.cc](https://img.shields.io/badge/html-icml.cc-2494E0.svg)](https://icml.cc/virtual/2025/poster/40129) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2503.10694-b31b1b.svg)](http://arxiv.org/abs/2503.10694) | :heavy_minus_sign: |
